from fastapi import FastAPI
from pydantic import BaseModel
import joblib
import numpy as np
from app.servicios.analisis_horarios import calcular_afluencia
from fastapi.middleware.cors import CORSMiddleware
from app.servicios.preparar_dataset import preparar_dataset_facturas
from app.servicios.preparar_clientes import obtener_datos_clientes  # 游녣 Importa esta nueva funci칩n
from app.servicios.ocupacion import obtener_ocupacion_actual
from app.servicios.parqueaderos import obtener_parqueaderos
from app.servicios.prediccion_prophet import preparar_datos_prophet, predecir_afluencia_prophet
from fastapi import APIRouter, Query, Body
from app.servicios.dynamodb_service import escanear_tickets
from app.servicios.prediccion_prophet import (
    transformar_tickets_dynamodb_a_prophet,
    predecir_afluencia_prophet,
    detectar_horas_activas 
)
from typing import Optional
from openai import OpenAI
import os
from dotenv import load_dotenv
from fastapi.responses import JSONResponse


class ImagenRequest(BaseModel):
    base64_img: str
    prompt: str


client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
app = FastAPI()
router = APIRouter()

# Habilitar CORS para que el frontend (Angular) acceda
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Puedes poner la URL exacta de tu frontend si prefieres
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Cargar modelo
modelo = joblib.load("modelo_volvera.joblib")

# Esquema de entrada para predicci칩n
class ClienteData(BaseModel):
    frecuencia: int
    recencia: int
    monto_total: float

@app.post("/predecir")
def predecir(data: ClienteData):
    entrada = np.array([[data.frecuencia, data.recencia, data.monto_total]])
    pred = modelo.predict(entrada)[0]
    prob = modelo.predict_proba(entrada)[0][1]
    return {
        "volvera": bool(pred),
        "probabilidad": round(float(prob), 4)
    }

# NUEVO: Endpoint para afluencia por hora y d칤a
@app.get("/afluencia")
def afluencia(
    fecha_inicio: str = Query(None),
    fecha_fin: str = Query(None),
    parqueadero_id: str = Query(None)
):
    return calcular_afluencia(
        fecha_inicio=fecha_inicio,
        fecha_fin=fecha_fin,
        parqueadero_id=parqueadero_id
    )


@app.get("/clientes-probables")
def clientes_probables():
    df = preparar_dataset_facturas()
    clientes_df = obtener_datos_clientes()

    X = df[["frecuencia", "recencia", "monto_total"]]
    df["probabilidad"] = modelo.predict_proba(X)[:, 1]
    df["volvera"] = modelo.predict(X)

    # Enlaza con info de clientes
    df = df.merge(clientes_df, on="clienteId", how="left")

    columnas = [
        "clienteId", "nombre_completo", "email",
        "frecuencia", "recencia", "monto_total", "volvera", "probabilidad"
    ]

    df = df[columnas].sort_values(by="probabilidad", ascending=False).head(20)

    # Convertir valores no serializables a tipos nativos
    df = df.fillna("")  # Evita errores por NaN
    df = df.astype({
        "clienteId": str,
        "nombre_completo": str,
        "email": str,
        "frecuencia": int,
        "recencia": int,
        "monto_total": float,
        "volvera": int,
        "probabilidad": float
    })

    return df.to_dict(orient="records")

@app.get("/ocupacion-real")
def ocupacion_real():
    return obtener_ocupacion_actual()


@app.get("/clientes-segmentados")
def clientes_segmentados():
    df = preparar_dataset_facturas()

    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler

    # Datos de entrada para clustering
    X = df[["frecuencia", "recencia", "monto_total"]]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Clustering
    kmeans = KMeans(n_clusters=3, random_state=42)
    df["grupo"] = kmeans.fit_predict(X_scaled)

    # Agregaci칩n por grupo
    resumen = df.groupby("grupo").agg(
        cantidad=("clienteId", "count"),
        frecuencia_promedio=("frecuencia", "mean"),
        recencia_promedio=("recencia", "mean"),
        monto_promedio=("monto_total", "mean")
    ).reset_index()

    # Etiquetas simples
    def etiquetar(row):
        if row["frecuencia_promedio"] > 5 and row["recencia_promedio"] < 30:
            return "Fieles"
        elif row["recencia_promedio"] > 100:
            return "Inactivos"
        else:
            return "Ocasionales"

    resumen["etiqueta"] = resumen.apply(etiquetar, axis=1)

    # Redondear valores
    resumen = resumen.round(2)

    return resumen.to_dict(orient="records")

@app.get("/parqueaderos")
def parqueaderos():
    return obtener_parqueaderos()

@app.get("/afluencia-predicha-prophet")
def afluencia_predicha_prophet(
    parqueadero_id: Optional[str] = Query(None),
    dias: int = 7,
    actualizar: bool = Query(False)
):
    try:
        items = escanear_tickets(force_reload=actualizar)
        print(f"Se trajeron {len(items)} tickets desde DynamoDB")
        df = transformar_tickets_dynamodb_a_prophet(items, estacionamiento_id=parqueadero_id)

        # --- INICIA DIAGN칍STICO ---
        print("俱뫮잺  [Diagn칩stico] Resumen estad칤stico de afluencia por hora:")
        print(df["y"].describe())
        print("俱뫮잺  Horas con y = 0:", (df["y"] == 0).sum())
        print("俱뫮잺  Horas totales:", len(df))
        print("俱뫮잺  Primeros datos:\n", df.head(10))
        print("俱뫮잺  칔ltimos datos:\n", df.tail(10))
        df['hora'] = df['ds'].dt.hour
        df['dia_semana'] = df['ds'].dt.dayofweek  # 0=lunes, 6=domingo
        print("俱뫮잺  Afluencia promedio por hora:")
        print(df.groupby('hora')["y"].mean().round(2))
        print("俱뫮잺  Afluencia promedio por d칤a (0=Lunes):")
        print(df.groupby('dia_semana')["y"].mean().round(2))

        if df.empty:
            return {
                "prediccion": [],
                "error": {"mae": None, "mape": None, "n": 0},
                "mensaje": "No hay datos suficientes para ese parqueadero"
            }

        # --- NUEVO: Detecci칩n autom치tica de horas activas ---
        horas_activas = detectar_horas_activas(df, umbral=10, min_dias=0.2)
        print(f"俱뫮잺  Horas activas detectadas: {horas_activas}")

        df_filtrado = df[df['ds'].dt.hour.isin(horas_activas)].copy()

        if df_filtrado.empty:
            return {
                "prediccion": [],
                "error": {"mae": None, "mape": None, "n": 0},
                "mensaje": "No hay datos suficientes en las horas activas para ese parqueadero"
            }

        # --- LLAMA A PROPHET SOLO CON HORAS ACTIVAS ---
        prediccion = predecir_afluencia_prophet(df_filtrado, dias_a_predecir=dias)
        return prediccion
    
    except Exception as e:
        # Esto asegura que NUNCA devuelve un 500 sino siempre JSON con mensaje de error
        return JSONResponse(
            status_code=200,
            content={
                "prediccion": [],
                "error": {"mae": None, "mape": None, "n": 0},
                "mensaje": f"Error interno: {str(e)}"
            }
        )

@router.post("/interpretar-afluencia", tags=["IA"])
def interpretar_afluencia(datos: list = Body(...)):
    prompt = (
        "Analiza esta tabla de predicci칩n de afluencia horaria por d칤a en un parqueadero. "
        "La tabla representa la cantidad estimada de personas que usar치n el parqueadero en cada hora de cada d칤a de la semana (siguientes 7 d칤as). "
        "Importante: **solo se muestran las horas en las que el parqueadero est치 operativo**. "
        "No consideres franjas con afluencia cero como horas valle si est치n fuera del horario de atenci칩n.\n\n"
        "Quiero que generes un resumen ejecutivo que incluya:\n"
        "1. Horarios o d칤as con mayor afluencia estimada (picos pr칩ximos).\n"
        "2. Riesgo de sobreocupaci칩n seg칰n los valores estimados.\n"
        "3. Recomendaciones para reforzar turnos operativos, seguridad o mantenimiento.\n"
        "4. Sugerencias de promociones para horas de baja afluencia que s칤 est치n dentro del horario laboral.\n\n"
        "Devuelve un an치lisis claro, corto, en vi침etas, 칰til para un gerente que necesita tomar decisiones r치pidamente. No incluyas explicaciones t칠cnicas.\n\n"
        f"Datos:\n{datos}"
    )

    try:
        respuesta = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Eres un analista de datos experto en gesti칩n de parqueaderos urbanos."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=3000
        )
        return {"interpretacion": respuesta.choices[0].message.content}
    except Exception as e:
        return {"error": str(e)}

    
app.include_router(router)

@app.post("/analizar-imagen")
def analizar_imagen(data: ImagenRequest):
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": data.prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": data.base64_img
                            }
                        }
                    ]
                }
            ],
            max_tokens=800
        )
        return {"respuesta": response.choices[0].message.content}
    except Exception as e:
        return {"error": str(e)}

